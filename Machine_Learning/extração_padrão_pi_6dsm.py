# -*- coding: utf-8 -*-
"""Extração_Padrão_PI_6dsm.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1wKG0B_i7_xYtlKcC-Kfiphr9_FYpsmpX

## **Extração Padrão PI - 6° Semestre**

---


**Integrantes do Grupo:**
* Camilli Ramos dos Santos
* Ana Beatriz dos Santos
* Moisés Verissimo de Souza

**Link base consumida:**

 https://www.kaggle.com/datasets/kaushil268/disease-prediction-using-machine-learning


**Informações Base de Dados**
* **Descrição:** Disease Prediction Using Machine Learning (Previsão de Doenças)
* **Quantidade de atributos:** 133
* **Quantidade de registros:** 4920
* **Doenças Previstas(Classe):** 42
* **Breve descrição:**
Um conjunto de dados com intuito de fornecer o diagnótico de uma possível doença, caso a mesma possua sintomas de uma doença específica ou esteja saudável, a base de dados usará os sintomas informado pelo paciente afim de prever o diagósntico.

  Para esta conclusão são fornecidos 133 tipos de sintomas(atributos) com valores igual a: **1** - (Possui sintoma) / **0** - (Não possui sintoma)
  
  Logo, deve ser fornecido pelo paciente conforme suas dores.
"""

from google.colab import drive
drive.mount('/content/drive/')

"""Importando bibliotecas e o DataFrame gerado pelo Pré-Processamento."""

# Commented out IPython magic to ensure Python compatibility.
# IMPORTANDO TODAS AS BIBLIOTECAS IMPORTANTES PARA CÁLCULO E CRIAÇÃO DE VISUALIZAÇÃO GRÁFICA
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
# %matplotlib inline
import seaborn as sns
import plotly.express as px
from pandas.plotting import scatter_matrix
from sklearn import model_selection
from sklearn.metrics import classification_report
from sklearn.metrics import confusion_matrix
from sklearn.metrics import accuracy_score
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis
from sklearn.naive_bayes import GaussianNB
from sklearn.svm import SVC

# IMPORTANDO ARQUIVO
df = pd.read_csv('/content/drive/My Drive/PI - 6 DSM/previsao_doencas.csv')
df.head()

"""### **Informações do DataFrame**

  Neste processo realizamos a listagem de informações relacionadas ao DataFreme, logo o objetivo é realizar uma análise dos dados após o Pré-processamento
"""

# DIMENSÃO
print(df.shape)

################################################################################

# RESUMO ESTATÍSTICO
print(df.describe())

################################################################################

# DISTRIBUIÇÃO DE CLASSE
print(df.groupby('prognostico').size())

"""### **Visualização dos dados**

Neste processo geramos os gráficos referente as informações do conjunto de dados
"""

#GRÁFICO DE BOX AND WHISKER
df.plot(kind='box', subplots=True, layout=(2,134), sharex=False, sharey=False)
plt.show()

################################################################################

# HISTOGRAMA
df.hist()
plt.show()

################################################################################

# GRÁFICO DE DISPERSÃO
scatter_matrix(df)
plt.show()

"""### **Criar conjunto de validação**

  Após uma análise cuidadosa dos dados do DataFreme, avançamos para a etapa de seleção e preparação do conjunto de validação. Este conjunto, essencial para garantir a precisão e a generalização dos modelos construídos, consiste em uma parcela estratégica dos dados originalmente coletados.
"""

# CONJUNTO DE VALIDAÇÃO
X = df.drop('prognostico', axis=1)
Y = df['prognostico']
validation_size = 0.20
seed = 7
X_train, X_validation, Y_train, Y_validation = model_selection.train_test_split(X, Y, test_size=validation_size, random_state=seed)

print(X_train.shape)
print(Y_train.shape)

print(X_validation.shape)
print(Y_validation.shape)

# MÉTRICAS
seed = 7
scoring = 'accuracy'

"""### Regressão Logística (LR)
### Análise Linear Discriminante (LDA)
### K-vizinhos mais próximos (KNN)
### Árvores de Classificação (Decision Tree) e Regressão (CART)
### Gaussian Naive Bayes (NB)
### Support Vector Machines (SVM)
"""

# ALGORITMOS
models = []
models.append(('LR', LogisticRegression(solver='liblinear', multi_class='ovr')))
models.append(('LDA', LinearDiscriminantAnalysis()))
models.append(('KNN', KNeighborsClassifier()))
models.append(('CART', DecisionTreeClassifier()))
models.append(('NB', GaussianNB()))
models.append(('SVM', SVC(gamma='auto')))

# AVALIAÇÃO DE CADA MODELO
results = []
names = []
for name, model in models:
   kfold = model_selection.KFold(n_splits=10, shuffle=True, random_state=42)
   cv_results = model_selection.cross_val_score(model, X_train, Y_train, cv=kfold, scoring='accuracy')
   results.append(cv_results)
   names.append(name)
   msg = '%s: %f (%f)' % (name, cv_results.mean(), cv_results.std())
   print(msg)

   #print(cv_results)

"""## **Análise de Algoritmos**

  Nesta etapa crucial, procedemos com a comparação dos algoritmos em relação aos dados do DataFreme, utilizando o gráfico para visualizar suas performances. Cada algoritmo obteve distintos padrões de desempenho no processo de aprendizado. Através da comparação direta, podemos identificar quais algoritmos se destacam em termos de precisão, eficiência computacional e capacidade de generalização. Logo, esta análise serve para orientar na seleção do modelo mais adequado para as necessidades específicas do projeto de previsão de doenças.

"""

# COMPARAÇÃO DOS ALGORITMOS
fig = plt.figure()
fig.suptitle('Algorithm Comparison')
ax = fig.add_subplot(111)
plt.boxplot(results)
ax.set_xticklabels(names)
plt.show()

"""## **Algoritmo - LR**
---
Aprendizagem - 100%
"""

# MODELO => LR
lr = LogisticRegression(solver='liblinear', multi_class='ovr')
lr.fit(X_train, Y_train)
predictions = lr.predict(X_validation)

print()
print(accuracy_score(Y_validation, predictions))
print(confusion_matrix(Y_validation, predictions))
print(classification_report(Y_validation, predictions, zero_division=1))

"""## **Algoritmo - LDA**
---
Aprendizagem - 99%
"""

# MODELO => LDA
lda = LinearDiscriminantAnalysis()
lda.fit(X_train, Y_train)
predictions = lda.predict(X_validation)

print()
print(accuracy_score(Y_validation, predictions))
print(confusion_matrix(Y_validation, predictions))
print(classification_report(Y_validation, predictions, zero_division=1))

"""## **Algoritmo - KNN**
---
Aprendizagem - 100%
"""

# MODELO => KNN
knn = KNeighborsClassifier(n_neighbors=3, weights='distance')
knn.fit(X_train, Y_train)
predictions = knn.predict(X_validation)

print()
print(accuracy_score(Y_validation, predictions))
print(confusion_matrix(Y_validation, predictions))
print(classification_report(Y_validation, predictions, zero_division=1))

"""## **Algoritmo - CART**
---
Aprendizagem - 98%
"""

# MODELO => CART
dtc = DecisionTreeClassifier()
dtc.fit(X_train, Y_train)
predictions = dtc.predict(X_validation)

print()
print(accuracy_score(Y_validation, predictions))
print(confusion_matrix(Y_validation, predictions))
print(classification_report(Y_validation, predictions, zero_division=1))

"""## **Algoritmo - NB**
---
Aprendizagem - 99%
"""

# MODELO => NB
nb = GaussianNB()
nb.fit(X_train, Y_train)
predictions = nb.predict(X_validation)

print()
print(accuracy_score(Y_validation, predictions))
print(confusion_matrix(Y_validation, predictions))
print(classification_report(Y_validation, predictions, zero_division=1))

"""## **Algoritmo - SVM**
---
Aprendizagem - 100%
"""

# MODELO => SVM
svm = SVC(gamma='auto')
svm.fit(X_train, Y_train)
predictions = svm.predict(X_validation)
print()
print(accuracy_score(Y_validation, predictions))
print(confusion_matrix(Y_validation, predictions))
print(classification_report(Y_validation, predictions, zero_division=1))

"""## **Importando Algoritmo junto ao DataFrame**

  Após uma análise detalhada dos algoritmos disponíveis, identificamos o modelo mais eficaz para o nosso conjunto de dados: o algoritmo de Árvores de Classificação e Regressão (CART), que alcançou uma taxa de acerto de 98%. Com base nesse desempenho, decidimos adotá-lo como o algoritmo de aprendizado de máquina para a nossa base de dados.
  
  Para chegar a essa conclusão realizamos uma série de testes e ajustes, incluindo a seleção de atributos por meio da remoção de colunas irrelevantes, a padronização dos valores da base de dados (substituindo por exemplo, 0 para "não" e 1 para "sim") e a adição de um sorteador para distribuição de respostas das classes. Certas modificações não foram implementadas, contudo, foram fundamentais para encontrar um algoritmo com o melhor desempenho possível. O processo de otimização contribuiu significativamente para um resultado preciso e satisfatório.
"""

from sklearn.tree import DecisionTreeClassifier

cart = DecisionTreeClassifier()
cart.fit(X_train, Y_train)

# EXPORTANDO ARQUIVO DATAFRAME COM ALGORITMO
import joblib
joblib.dump(cart, '/content/drive/MyDrive/PI - 6 DSM/cart.pkl')